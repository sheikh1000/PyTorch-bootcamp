{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01724f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchmetrics import Accuracy\n",
    "from torch import nn\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchinfo import summary\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import random\n",
    "\n",
    "from pathlib import Path\n",
    "import zipfile\n",
    "import requests\n",
    "import os\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf4f9ea",
   "metadata": {},
   "source": [
    "> #### Defining the paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6eb24b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import importlib.util\n",
    "\n",
    "modules_path = 'PyTorch Bootcamp--06 -Transfer Learning/'\n",
    "sys.path.append(modules_path)\n",
    "module_names = ['data_setup', 'engine']\n",
    "modules = {}\n",
    "for module_name in module_names:\n",
    "    spec = importlib.util.find_spec(module_name)\n",
    "    if spec is not None:\n",
    "        modules[module_name] = importlib.util.module_from_spec(spec)\n",
    "        spec.loader.exec_module(modules[module_name])\n",
    "    else:\n",
    "        print(f\"Module '{module_name}' not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79ea9239",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_setup import create_dataloaders\n",
    "from engine import train_step, test_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d98d73df",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path('data/')\n",
    "image_path = data_path / 'pizza_steak_sushi'\n",
    "image_paths_list = list(image_path.glob('*/*/*.jpg'))\n",
    "\n",
    "train_path = image_path / 'train'\n",
    "test_path = image_path / 'test'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9dd04f",
   "metadata": {},
   "source": [
    "> #### Automatic transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0537244",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader, test_dataloader, class_names = create_dataloaders(\n",
    "    train_path, test_path,\n",
    "    transform=torchvision.models.EfficientNet_B0_Weights.DEFAULT.transforms(),\n",
    "    batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39cb8cbf",
   "metadata": {},
   "source": [
    "> ### Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef69277c",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "051c11c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model: torch.nn.Module, \n",
    "          train_dataloader: torch.utils.data.DataLoader, \n",
    "          test_dataloader: torch.utils.data.DataLoader, \n",
    "          optimizer: torch.optim.Optimizer,\n",
    "          loss_fn: torch.nn.Module,\n",
    "          epochs: int) -> Dict[str, List]:\n",
    "    \n",
    "    results = {\"train_loss\": [],\n",
    "               \"train_acc\": [],\n",
    "               \"test_loss\": [],\n",
    "               \"test_acc\": []\n",
    "              }\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        train_loss, train_acc = train_step(model=model,\n",
    "                                           dataloader=train_dataloader,\n",
    "                                           loss_fn=loss_fn,\n",
    "                                           optimizer=optimizer)\n",
    "        \n",
    "        test_loss, test_acc = test_step(model=model,\n",
    "                                        dataloader=test_dataloader,\n",
    "                                        loss_fn=loss_fn)\n",
    "        \n",
    "        print(f\"Epoch: {epoch+1} | train_loss: {train_loss:.4f} | train_acc: {train_acc:.4f} |\"\n",
    "          f\"test_loss: {test_loss:.4f} | \" f\"test_acc: {test_acc:.4f}\")\n",
    "        \n",
    "        results[\"train_loss\"].append(train_loss)\n",
    "        results[\"train_acc\"].append(train_acc)\n",
    "        results[\"test_loss\"].append(test_loss)\n",
    "        results[\"test_acc\"].append(test_acc)\n",
    "        \n",
    "        writer.add_scalars(main_tag='Loss',\n",
    "                          tag_scalar_dict={\"train_loss\": train_loss,\n",
    "                                           \"test_loss\": test_loss},\n",
    "                          global_step=epoch)\n",
    "        \n",
    "        writer.add_scalars(main_tag='Accuracy',\n",
    "                          tag_scalar_dict={\"train_acc\": train_acc,\n",
    "                                           \"test_acc\": test_acc},\n",
    "                          global_step=epoch)\n",
    "        \n",
    "        writer.add_graph(model=model,\n",
    "                        input_to_model=torch.rand(32, 3, 224, 224))\n",
    "        \n",
    "    writer.close()\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ee201b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT\n",
    "\n",
    "eff_net_model = torchvision.models.efficientnet_b0(weights=weights)\n",
    "\n",
    "for param in eff_net_model.features.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "eff_net_model.classifier = nn.Sequential(\n",
    "    nn.Dropout(p=0.2, inplace=True),\n",
    "    nn.Linear(in_features=1280, out_features=3, bias=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "41bac514",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 4\n",
    "BATCH_SIZE = 32\n",
    "learning_rate = 0.001\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(eff_net_model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5c2a9021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | train_loss: 1.0648 | train_acc: 0.4688 |test_loss: 0.8456 | test_acc: 0.7453\n",
      "Epoch: 2 | train_loss: 0.8869 | train_acc: 0.6484 |test_loss: 0.7051 | test_acc: 0.8561\n",
      "Epoch: 3 | train_loss: 0.7512 | train_acc: 0.7539 |test_loss: 0.6952 | test_acc: 0.8258\n",
      "Epoch: 4 | train_loss: 0.6917 | train_acc: 0.7461 |test_loss: 0.6304 | test_acc: 0.8665\n"
     ]
    }
   ],
   "source": [
    "model_results = train(epochs=EPOCHS, model=eff_net_model,\n",
    "                      train_dataloader=train_dataloader, test_dataloader=test_dataloader,\n",
    "                      loss_fn=loss_fn, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9387bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir runs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
